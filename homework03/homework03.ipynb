{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92771872-f74d-4436-a89a-336d4d452eb3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Homework 3: Wordnet\n",
    "\n",
    "WordNet is a project that began at Princeton in 1985 and was originally intended to be a tool to support research that theorized the nature of semantic human memory. It consists of a large database of words and their glosses (definitions), attributes and relationships to other words, and somee example usages. There exist wrappers to access it in most languages, including one built in to `nltk` in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1e898f51-8f58-411a-a257-1c73782f7f3f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('immunology.n.01')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"wordnet\", quiet=True)\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "import random\n",
    "\n",
    "nouns = [ n.name().split(\".\")[0] for n in wn.all_synsets(\"n\") ]\n",
    "word = random.choice(nouns)\n",
    "syns = wn.synsets(word, wn.NOUN)\n",
    "print(syns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c64ed2f9-cb46-4ea0-abd0-983bbea326f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the branch of medical science that studies the body's immune system\n",
      "[]\n",
      "[Lemma('immunology.n.01.immunology')]\n",
      "[Synset('medicine.n.01'), Synset('medical_science.n.01'), Synset('life_science.n.01'), Synset('natural_science.n.01'), Synset('science.n.01'), Synset('discipline.n.01'), Synset('knowledge_domain.n.01'), Synset('content.n.05'), Synset('cognition.n.01'), Synset('psychological_feature.n.01'), Synset('abstraction.n.06'), Synset('entity.n.01')]\n"
     ]
    }
   ],
   "source": [
    "synset = random.choice(syns)\n",
    "print(synset.definition())\n",
    "print(synset.examples())\n",
    "print(synset.lemmas())\n",
    "\n",
    "top = wn.synset(\"entity.n.01\")\n",
    "print(list(synset.closure(lambda s: s.hypernyms() if not s == top else [])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be3435d-9700-4167-bd25-a211777bec64",
   "metadata": {},
   "source": [
    "Nouns generally have a fairly straightforward derivation toward `entity.n.01`, as shown in the generalization of \"immunology\" into \"medicine\", medical science\", etc. While termination is guaranteed for nouns, this is not necessarily so for verbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f798b927-8526-4e02-8ff1-e532f419c234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('medicine.n.01')]\n",
      "[Synset('immunochemistry.n.01'), Synset('immunopathology.n.01')]\n",
      "[]\n",
      "[]\n",
      "[[]]\n"
     ]
    }
   ],
   "source": [
    "print(synset.hypernyms())\n",
    "print(synset.hyponyms())\n",
    "print(synset.member_meronyms() + synset.substance_meronyms() + synset.part_meronyms())\n",
    "print(synset.member_holonyms() + synset.substance_holonyms() + synset.part_holonyms())\n",
    "print([ l.antonyms() for l in synset.lemmas() ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6d0205e0-bdd5-46da-8286-a4a586442ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('puree.v.01')]\n"
     ]
    }
   ],
   "source": [
    "verbs = [ v.name().split(\".\")[0] for v in wn.all_synsets(\"v\") ]\n",
    "verb = random.choice(verbs)\n",
    "syns = wn.synsets(verb, wn.VERB)\n",
    "print(syns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "23183ef6-7bd2-427c-b8dc-8e019618e69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rub through a strainer or process in an electric blender\n",
      "['puree the vegetables for the baby']\n",
      "[Lemma('puree.v.01.puree'), Lemma('puree.v.01.strain')]\n",
      "[Synset('rub.v.01'), Synset('guide.v.05')]\n"
     ]
    }
   ],
   "source": [
    "synset = random.choice(syns)\n",
    "print(synset.definition())\n",
    "print(synset.examples())\n",
    "print(synset.lemmas())\n",
    "\n",
    "print(list(synset.closure(lambda s: s.hypernyms())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a36a1d-e3a9-47c1-9ef0-5a1e59002251",
   "metadata": {},
   "source": [
    "The hierarchy for verbs is much more shallow, with this word only having two iterations. Unlike nouns, I suppose it's not as easy to generalize actions without delving into archaic etymology. That also explains why there is no top level verb synset akin to `entity.n.01`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ff052cfc-6fc4-42b3-8264-ddd5b71a6d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "puree\n",
      "puree\n"
     ]
    }
   ],
   "source": [
    "for pos in [ wn.NOUN, wn.VERB, wn.ADJ, wn.ADV ]:\n",
    "    if not wn.morphy(verb, pos) == None:\n",
    "        print(wn.morphy(verb, pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "94998c67-a309-46df-b115-416541a4cc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n",
      "Synset('recover.v.01')\n",
      "Synset('situate.v.01')\n"
     ]
    }
   ],
   "source": [
    "from nltk.wsd import lesk\n",
    "\n",
    "words = ( \"find\", \"locate\")\n",
    "syns = ( wn.synset(\"find.v.03\"), wn.synset(\"locate.v.01\") )\n",
    "\n",
    "print(wn.wup_similarity(syns[0], syns[1]))\n",
    "print(lesk(syns[0].examples()[0].split(\" \"), words[0]))\n",
    "print(lesk(syns[1].examples()[0].split(\" \"), words[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13619cd3-e406-422e-80b3-e85de9ebb91a",
   "metadata": {},
   "source": [
    "The Wu-Palmer metric of 0.8 indicates that the two words are pretty similar, as I expected. The Lesk result for \"find\" isn't too surprising, but \"situate\", in the sense it is used, seems somewhat different from \"locate\", even considering the context of the example sentence in which it was used (\"Can you locate your cousins in the Midwest?\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782a048f-fce5-4de7-a4e4-834e19bd17b0",
   "metadata": {},
   "source": [
    "## SentiWordNet\n",
    "\n",
    "SentiWordNet assigns scores of positivity, negativity, and objectivity to approximate how provocative words are and in what sense. This is useful in getting a general idea of how instigative a text might be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4f775d5b-072e-4d21-89bb-491425befbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.125\n",
      "0.0\n",
      "0.875\n",
      "light: 0.0, 0.0, 1.0\n",
      "through: 0.0, 0.0, 1.0\n",
      "yonder: 0.125, 0.0, 0.875\n",
      "window: 0.0, 0.0, 1.0\n",
      "breaks: 0.0, 0.0, 1.0\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"sentiwordnet\", quiet=True)\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "\n",
    "word = swn.senti_synset(\"fucking.r.01\")\n",
    "print(word.pos_score())\n",
    "print(word.neg_score())\n",
    "print(word.obj_score())\n",
    "\n",
    "sentence = [ \"what\", \"light\", \"through\", \"yonder\", \"window\", \"breaks\" ]\n",
    "for w in sentence:\n",
    "    syns = wn.synsets(w)\n",
    "    if len(syns) < 1:\n",
    "        continue\n",
    "    ss = swn.senti_synset(syns[0].name())\n",
    "    print(f\"{w}: {ss.pos_score()}, {ss.neg_score()}, {ss.obj_score()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd040fd9-81a8-49f6-abfe-8e5b30a3c11d",
   "metadata": {},
   "source": [
    "I'm surprised \"fucking\" is regarded as having a positive connotation over a negative one, but otherwise nothing else is too surprising. The sentence having a vaguely positive tone seems apt, even if the methodology in doing so was rather careless (taking the first sense of the word). Being able to programmatically discern subtleties like this can prove useful in fields like content moderation, though systems may fail to recognize certain nuances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d26de1-82f1-463c-97c9-326af0ae9435",
   "metadata": {},
   "source": [
    "## Collocations\n",
    "\n",
    "Collocations are two or more words that are generally used together, where substituting one of the words for a synonym would not convey the same meaning. These can pose issues for language processing since they don't conform to the generic rules of language and may not always be obvious without cultural context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "3014c160-5019-4342-8275-25f0964a7f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States; fellow citizens; years ago; four years; Federal\n",
      "Government; General Government; American people; Vice President; God\n",
      "bless; Chief Justice; one another; fellow Americans; Old World;\n",
      "Almighty God; Fellow citizens; Chief Magistrate; every citizen; Indian\n",
      "tribes; public debt; foreign nations\n",
      "None\n",
      "9.357832298914353\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"gutenberg\", quiet=True)\n",
    "nltk.download(\"genesis\", quiet=True)\n",
    "nltk.download(\"inaugural\", quiet=True)\n",
    "nltk.download(\"nps_chat\", quiet=True)\n",
    "nltk.download(\"webtext\", quiet=True)\n",
    "nltk.download(\"treebank\", quiet=True)\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "from nltk.book import text4\n",
    "import math\n",
    "\n",
    "print(text4.collocations())\n",
    "\n",
    "coll = ( \"years\", \"ago\" )\n",
    "bigrams = list(nltk.bigrams(text4))\n",
    "n_bigrams = len(bigrams)\n",
    "n_tokens = len(text4)\n",
    "\n",
    "Pxy = bigrams.count(coll) / n_bigrams\n",
    "Px = text4.count(coll[0]) / n_tokens\n",
    "Py = text4.count(coll[1]) / n_tokens\n",
    "print(math.log(Pxy / (Px * Py), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615068fc-098b-41e4-bc44-2ea7c5773ad2",
   "metadata": {},
   "source": [
    "The point-wise mutual information value of 9.3578 indicates that there was some positive association between the two words. To what _degree_ there is an association however, I'm not really too sure. Without getting into the nitty-gritty of the specific maximum value possible, 9.3578 seems like a value well above 0 (independent) to the point where I would trust that there is a substantial connection there."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
